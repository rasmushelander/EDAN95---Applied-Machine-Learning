// The Decision Tree
digraph {
	0 [label="
id: 0
label: +
attribute: size
entropy: 0.9886994082884974
samples: 16
classCounts: [9, 7]"]
	1 [label="
id: 1
label: +
attribute: shape
entropy: 0.8112781244591328
samples: 8
classCounts: [6, 2]"]
	2 [label="
id: 2
label: +
attribute: color
entropy: 0.9182958340544896
samples: 6
classCounts: [4, 2]"]
	3 [label="
id: 3
value: y
label: +
entropy: 0.7219280948873623
samples: 5
classCounts: [4, 1]"]
	2 -> 3
	4 [label="
id: 4
label: -
entropy: -0.0
samples: 1
classCounts: [0, 1]"]
	4 [label="
id: 4
value: g
label: -
entropy: -0.0
samples: 1
classCounts: [0, 1]"]
	2 -> 4
	2 [label="
id: 2
value: r
label: +
attribute: color
entropy: 0.9182958340544896
samples: 6
classCounts: [4, 2]"]
	1 -> 2
	5 [label="
id: 5
value: i
label: +
entropy: -0.0
samples: 2
classCounts: [2, 0]"]
	1 -> 5
	1 [label="
id: 1
value: s
label: +
attribute: shape
entropy: 0.8112781244591328
samples: 8
classCounts: [6, 2]"]
	0 -> 1
	6 [label="
id: 6
label: -
attribute: color
entropy: 0.9544340029249649
samples: 8
classCounts: [3, 5]"]
	7 [label="
id: 7
label: -
attribute: shape
entropy: 0.9852281360342516
samples: 7
classCounts: [3, 4]"]
	8 [label="
id: 8
value: r
label: -
entropy: 0.9182958340544896
samples: 6
classCounts: [2, 4]"]
	7 -> 8
	9 [label="
id: 9
label: +
entropy: -0.0
samples: 1
classCounts: [1, 0]"]
	9 [label="
id: 9
value: i
label: +
entropy: -0.0
samples: 1
classCounts: [1, 0]"]
	7 -> 9
	7 [label="
id: 7
value: y
label: -
attribute: shape
entropy: 0.9852281360342516
samples: 7
classCounts: [3, 4]"]
	6 -> 7
	10 [label="
id: 10
label: -
entropy: -0.0
samples: 1
classCounts: [0, 1]"]
	10 [label="
id: 10
value: g
label: -
entropy: -0.0
samples: 1
classCounts: [0, 1]"]
	6 -> 10
	6 [label="
id: 6
value: l
label: -
attribute: color
entropy: 0.9544340029249649
samples: 8
classCounts: [3, 5]"]
	0 -> 6
}
